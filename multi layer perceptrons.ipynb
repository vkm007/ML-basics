{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2 # no of features\n",
    "layers = [4,3] # no of neurons in first and sencond layer\n",
    "output_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    e_pa = np.exp(a) \n",
    "    ans = e_pa/np.sum(e_pa, axis = 1, keepdims = True)\n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, layers, output_size):\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        model = {}\n",
    "        \n",
    "        #first layer\n",
    "        model['w1'] = np.random.randn(input_size, layers[0])\n",
    "        model['b1'] = np.zeros((1, layers[0]))\n",
    "        \n",
    "        #second layer\n",
    "        model['w2'] = np.random.randn(layers[0], layers[1])\n",
    "        model['b2'] = np.zeros((1, layers[1]))\n",
    "        \n",
    "        #output layer\n",
    "        model['w3'] = np.random.randn(layers[1], output_size)\n",
    "        model['b3'] = np.zeros((1, output_size))\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        W1, W2, W3 = self.model['w1'], self.model['w2'], self.model['w3']\n",
    "        b1, b2, b3 = self.model['b1'], self.model['b2'], self.model['b3']\n",
    "        \n",
    "        z1 = np.dot(x,W1)+b1\n",
    "        a1 = np.tanh(z1)\n",
    "        \n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        a2 = np.tanh(z2)\n",
    "        \n",
    "        z3 = np.dot(a2,W3) + b3\n",
    "        y_ = softmax(z3)\n",
    "        \n",
    "        self.activation_outputs = (a1,a2,y_)\n",
    "        return y_\n",
    "    \n",
    "    def backward(self, X, y,learning_rate = 0.001):\n",
    "        W1, W2, W3 = self.model['w1'], self.model['w2'], self.model['w3']\n",
    "        b1, b2, b3 = self.model['b1'], self.model['b2'], self.model['w3']\n",
    "        m = x.shape[0]\n",
    "        \n",
    "        a1,a2,y_ = self.activation_outputs\n",
    "        \n",
    "        delta3 = y_-y\n",
    "        dw3 = np.dot(a2.T, delta3)\n",
    "        db3 = np.sum(delta3, axis=0)/float(m)\n",
    "        \n",
    "        delta2 = (1-np.square(a2))*np.dot(delta3, W3.T)\n",
    "        dw2 = np.dot(a1.T,delta2)\n",
    "        db2 = np.sum(delta2, axis=0)/float(m)\n",
    "        \n",
    "        delta1 = (1-np.square(a1))*np.dot(delta2,W2.T)\n",
    "        dw1 = np.dot(X.T,delta1)\n",
    "        db1 = np.sum(delta1,axis=0)/float(m)\n",
    "        \n",
    "        \n",
    "        self.model['w1'] -=learning_rate*dw1\n",
    "        self.model['b1'] -=learning_rate*db1\n",
    "        \n",
    "        self.model['w2'] -=learning_rate*dw2\n",
    "        self.model['b2'] -=learning_rate*db2\n",
    "        \n",
    "        self.model['w3'] -=learning_rate*dw3\n",
    "        self.model['b3'] -=learning_rate*db3\n",
    "        \n",
    "        \n",
    "    def predict(self,x):\n",
    "        y_out = self.forward(x)\n",
    "        return np.argmax(y_out,axis = 1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_oht,p):\n",
    "    l = -np.mean(y_oht*np.log(p))\n",
    "    return l \n",
    "\n",
    "def one_hot(y, depth):\n",
    "    \n",
    "    m = y.shape[0]\n",
    "    y_oht = np.zeros((m,depth))\n",
    "    y_oht[np.arange(m),y] = 1\n",
    "\n",
    "    return y_oht\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,Y,model,epochs,learning_rate,logs = True):\n",
    "    training_loss = []\n",
    "    \n",
    "    classes = 2\n",
    "    y_oht = one_hot(Y,classes)\n",
    "    \n",
    "    for ix in range(epochs):\n",
    "        \n",
    "        y_ = model.forward(X)\n",
    "        l = loss(y_oht,y_)\n",
    "        training_loss.append(l)\n",
    "        model.backward(X,y_oht,learning_rate)\n",
    "        \n",
    "        if (logs):\n",
    "            print(\"epoch %d loss %f\"%(ix,l))\n",
    "            \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(input_size = 2, layers = [10,5], output_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.342702\n",
      "epoch 1 loss 0.255870\n",
      "epoch 2 loss 0.216245\n",
      "epoch 3 loss 0.194929\n",
      "epoch 4 loss 0.179687\n",
      "epoch 5 loss 0.165584\n",
      "epoch 6 loss 0.151407\n",
      "epoch 7 loss 0.137308\n",
      "epoch 8 loss 0.123851\n",
      "epoch 9 loss 0.111479\n",
      "epoch 10 loss 0.100397\n",
      "epoch 11 loss 0.090629\n",
      "epoch 12 loss 0.082098\n",
      "epoch 13 loss 0.074678\n",
      "epoch 14 loss 0.068228\n",
      "epoch 15 loss 0.062612\n",
      "epoch 16 loss 0.057707\n",
      "epoch 17 loss 0.053407\n",
      "epoch 18 loss 0.049621\n",
      "epoch 19 loss 0.046271\n",
      "epoch 20 loss 0.043296\n",
      "epoch 21 loss 0.040640\n",
      "epoch 22 loss 0.038260\n",
      "epoch 23 loss 0.036117\n",
      "epoch 24 loss 0.034182\n",
      "epoch 25 loss 0.032426\n",
      "epoch 26 loss 0.030828\n",
      "epoch 27 loss 0.029368\n",
      "epoch 28 loss 0.028031\n",
      "epoch 29 loss 0.026802\n",
      "epoch 30 loss 0.025670\n",
      "epoch 31 loss 0.024623\n",
      "epoch 32 loss 0.023653\n",
      "epoch 33 loss 0.022753\n",
      "epoch 34 loss 0.021915\n",
      "epoch 35 loss 0.021133\n",
      "epoch 36 loss 0.020403\n",
      "epoch 37 loss 0.019718\n",
      "epoch 38 loss 0.019076\n",
      "epoch 39 loss 0.018473\n",
      "epoch 40 loss 0.017905\n",
      "epoch 41 loss 0.017369\n",
      "epoch 42 loss 0.016863\n",
      "epoch 43 loss 0.016384\n",
      "epoch 44 loss 0.015931\n",
      "epoch 45 loss 0.015502\n",
      "epoch 46 loss 0.015094\n",
      "epoch 47 loss 0.014706\n",
      "epoch 48 loss 0.014337\n",
      "epoch 49 loss 0.013985\n",
      "epoch 50 loss 0.013650\n",
      "epoch 51 loss 0.013329\n",
      "epoch 52 loss 0.013023\n",
      "epoch 53 loss 0.012731\n",
      "epoch 54 loss 0.012451\n",
      "epoch 55 loss 0.012182\n",
      "epoch 56 loss 0.011924\n",
      "epoch 57 loss 0.011677\n",
      "epoch 58 loss 0.011440\n",
      "epoch 59 loss 0.011212\n",
      "epoch 60 loss 0.010992\n",
      "epoch 61 loss 0.010781\n",
      "epoch 62 loss 0.010577\n",
      "epoch 63 loss 0.010381\n",
      "epoch 64 loss 0.010191\n",
      "epoch 65 loss 0.010009\n",
      "epoch 66 loss 0.009832\n",
      "epoch 67 loss 0.009662\n",
      "epoch 68 loss 0.009497\n",
      "epoch 69 loss 0.009338\n",
      "epoch 70 loss 0.009183\n",
      "epoch 71 loss 0.009034\n",
      "epoch 72 loss 0.008889\n",
      "epoch 73 loss 0.008749\n",
      "epoch 74 loss 0.008613\n",
      "epoch 75 loss 0.008481\n",
      "epoch 76 loss 0.008353\n",
      "epoch 77 loss 0.008229\n",
      "epoch 78 loss 0.008108\n",
      "epoch 79 loss 0.007991\n",
      "epoch 80 loss 0.007877\n",
      "epoch 81 loss 0.007766\n",
      "epoch 82 loss 0.007658\n",
      "epoch 83 loss 0.007553\n",
      "epoch 84 loss 0.007451\n",
      "epoch 85 loss 0.007352\n",
      "epoch 86 loss 0.007255\n",
      "epoch 87 loss 0.007160\n",
      "epoch 88 loss 0.007068\n",
      "epoch 89 loss 0.006978\n",
      "epoch 90 loss 0.006891\n",
      "epoch 91 loss 0.006805\n",
      "epoch 92 loss 0.006722\n",
      "epoch 93 loss 0.006641\n",
      "epoch 94 loss 0.006561\n",
      "epoch 95 loss 0.006483\n",
      "epoch 96 loss 0.006408\n",
      "epoch 97 loss 0.006333\n",
      "epoch 98 loss 0.006261\n",
      "epoch 99 loss 0.006190\n"
     ]
    }
   ],
   "source": [
    "losses = train(X,Y,model,100,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy is 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "x_tr,y_tr = make_moons(n_samples = 500, noise = 0.2,random_state=1)\n",
    "\n",
    "model = NeuralNetwork(input_size = 2, layers = [8,4],output_size = 2)\n",
    "train(x_tr,y_tr,model,1000,0.001,logs=False)\n",
    "outputs = model.predict(x_tr)\n",
    "\n",
    "training_accuracy = np.sum(outputs == y_tr)/y_tr.shape[0]\n",
    "print('training_accuracy is', training_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
